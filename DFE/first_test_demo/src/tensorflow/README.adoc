= Horse vs Truck Image Classifier
Trung Thieu Quang <thieuquangtrung1999@gmail.com>
v0.1, 2025-05-23

A lightweight, self-contained TensorFlow project that distinguishes
images of horses from trucks.  It demonstrates:

* an object-oriented, modular code base (data → model → training)
* a custom `tf.data` pipeline that assigns binary labels without
  changing the on-disk folder structure
* early stopping and optional checkpointing
* configuration through a single `config.py` file

NOTE: All source code lives in `src/tensorflow/`.  Activate the Poetry
environment first: `poetry shell`.

== 1 Project layout

[source]
----
src/tensorflow/
 ├── config.py          # hyper-parameters & paths (single source of truth)
 ├── data.py            # HorseTruckData → three tf.data.Dataset objects
 ├── model.py           # HorseTruckCNN → small 3-block CNN
 ├── trainer.py         # Trainer wrapper with early stopping
 └── main.py            # orchestration script
----

== 2 Dataset layout on disk

We keep the original folder hierarchy and attach labels in code:

----
horse_images/
└─ data/
   ├─ train/   *.jpg   ← horse ⇒ label 0
   ├─ val/     *.jpg
   └─ test/    *.jpg

truck_images/
└─ data/
   ├─ train/   *.jpg   ← truck ⇒ label 1
   ├─ val/     *.jpg
   └─ test/    *.jpg
----

No sub-folders per class are required; `data.py` assigns the constant label
during streaming.

== 3 Configuration (`config.py`)

[cols="<2,<4",options="header"]
|===
|Field |Meaning

|`HORSE_DATA_DIR` `TRUCK_DATA_DIR`
|Root folders (point at the _data_ sub-folder inside each class).

|`BATCH_SIZE`     |Mini-batch size for all splits.
|`IMAGE_SIZE`     |Target height × width after resize.
|`SEED`           |Random seed for shuffling/reproducibility.

|`NUM_FILTERS`    |Tuple of filter counts per Conv block.
|`KERNEL_SIZE`    |Side length of square kernels.
|`DENSE_UNITS`    |Width of the dense layer after the CNN backbone.
|`DROPOUT`        |Dropout rate before the output layer.

|`EPOCHS`         |Maximum number of epochs.
|`EARLY_STOP`     |Stop if *validation* loss hasn’t improved for N epochs.
|`LEARNING_RATE`  |Initial learning-rate for Adam.
|===

== 4 Data pipeline (`data.py`)

[source,python]
----
class HorseTruckData:
    def load() -> (train, val, test):
        train = _from_roots(horse/train, truck/train, shuffle=True)
        ...
    def _from_roots(horse_dir, truck_dir):
        horse_ds = _one_class_ds(horse_dir, label=0)
        truck_ds = _one_class_ds(truck_dir, label=1)
        return (horse_ds + truck_ds).shuffle().cache().prefetch()
----
* `_one_class_ds` lists `*.jpg`, decodes, rescales to `[0,1]`,
  and attaches a constant label.
* All three splits are returned as ready-to-use `tf.data.Dataset` objects.

== 5 Model architecture (`model.py`)

[graphviz]
----
digraph CNN {
  rankdir=LR
  input [label="180×180×3\nInput"];
  rs     [label="Rescaling\n/255"];
  conv1  [label="Conv2D 32\nBN+ReLU\nMaxPool"];
  conv2  [label="Conv2D 64\nBN+ReLU\nMaxPool"];
  conv3  [label="Conv2D 128\nBN+ReLU\nMaxPool"];
  flat   [label="Flatten"];
  dense  [label="Dense 128\nBN+ReLU\nDropout 0.3"];
  out    [label="Dense 1\nSigmoid"];

  input->rs->conv1->conv2->conv3->flat->dense->out;
}
----
The final sigmoid outputs a probability ∈ [0,1]; threshold 0.5 ⇒ truck.

== 6 Training loop (`trainer.py` + `main.py`)

* Adam(learning-rate =`config.LEARNING_RATE`)
* Binary-cross-entropy loss
* EarlyStopping(patience =`EARLY_STOP`, restore_best_weights = True)
* Optional checkpoint to `./checkpoints/best.h5`

Run:

----
poetry run python main.py
----

At the end you’ll see a two-panel plot and a console line like:

----
✅  Test accuracy = 0.8734
----

== 7 Interpreting the history plot

image::docs/history_panel.png[align=center,width=600]

[cols="1,5",options="header"]
|===
|Curve |What it means

|`loss`
|Binary-cross-entropy averaged over the *training* mini-batches of the current epoch.

|`val_loss`
|Same metric, but computed on the **validation** set (data never
seen by the optimizer).

|`accuracy`
|Percentage of correct predictions on training mini-batches.

|`val_accuracy`
|Accuracy on the validation set.
|===

Desirable pattern:

* Both _loss_ curves decrease; both _accuracy_ curves increase.
* `val_*` closely tracks `train_*` with a small gap.
* Early-stopping halts training once `val_loss` hasn’t improved for
  `EARLY_STOP` epochs → prevents over-fitting.

Troubleshooting cheatsheet:

[cols="<2,<4"]
|===
|Symptom |Typical fix

|`train_loss` ↓ but `val_loss` ↑
|More dropout / L2, data augmentation, or stop earlier.

|Both losses high and parallel
|Model under-capacity → raise `NUM_FILTERS` or `DENSE_UNITS`.

|Training noisy
|Lower `LEARNING_RATE` or increase `BATCH_SIZE`.
|===

== 8 Extending the project

* Plug in a stronger backbone (e.g. `tf.keras.applications.EfficientNetB0`)
  inside `model.py`.
* Add image augmentations in `_load` (`tf.image.random_flip_left_right`, …).
* Convert to multi-class by changing `outputs = Dense(N, softmax)` and
  `loss="sparse_categorical_crossentropy"`.

Happy training!
