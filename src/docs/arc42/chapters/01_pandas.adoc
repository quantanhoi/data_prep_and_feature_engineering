:jbake-title: Pandas
:jbake-type: page_toc
:jbake-status: published
:jbake-menu: arc42
:jbake-order: 1
:filename: /chapters/01_pandas.adoc
ifndef::imagesdir[:imagesdir: ../../images]

:toc:



[[section-building-block-view]]


== Pandas

=== Data Access & Select

This document outlines common pandas functions for selecting and inspecting data, mirroring the style used in *03_scaling_numerical.adoc*. Use it as a quick reference for exploring and manipulating DataFrames.





==== df.head()
.Shows the first few rows of a DataFrame.
[source,python]
----
import pandas as pd

df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35]
})

print(df.head())  # By default, shows first 5 rows
----
*When to Use:*  
- Quickly inspect the top of a dataset to verify columns, data types, and sample records.

*When Not to Use:*  
- Large-scale data exploration beyond the first few rows.





==== df.tail()
.Shows the last few rows of a DataFrame.
[source,python]
----
import pandas as pd

df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Ethan'],
    'Score': [88, 92, 79, 85, 90]
})

print(df.tail(2))  # Shows the last 2 rows
----
*When to Use:*  
- Check recent rows, e.g., last few records in a time series.

*When Not to Use:*  
- Full data inspection or large-scale analysis.





==== df.describe()
.Provides summary statistics for numeric columns.
[source,python]
----
import pandas as pd

df = pd.DataFrame({
    'col1': [10, 20, 30],
    'col2': [5, 10, 15]
})

print(df.describe())
----
*When to Use:*  
- Get quick insight into count, mean, standard deviation, etc.

*When Not to Use:*  
- Investigating non-numeric columns in detail (it won’t summarize strings).


==== df.sort_index()
.Sorts a DataFrame by its index.
[source,python]
----
import pandas as pd
df = pd.DataFrame({
    'Name': ['Charlie', 'Bob', 'Alice'],
    'Age': [35, 30, 25]
}, index=[2, 1, 0])

sorted_df = df.sort_index()
print(sorted_df)
----
*When to Use:*
- When you need to order data based on the DataFrame's index.
- Useful for time series data or when the index is meaningful.
*When Not to Use:*
- When you need to sort by a specific column instead of the index; use `df.sort_values()` instead.




==== df.sort_values('col')
.Sorts a DataFrame by a specified column.
[source,python]
----
import pandas as pd

df = pd.DataFrame({
    'Name': ['Charlie', 'Bob', 'Alice'],
    'Age': [35, 30, 25]
})

sorted_df = df.sort_values('Age')
print(sorted_df)
----
*When to Use:*  
- Order data for better readability or to prepare for merges/joins.

*When Not to Use:*  
- Data that is too large for in-memory sorting.




==== .loc[row, col]
.Label-based data selection.
[source,python]
----
import pandas as pd

df = pd.DataFrame({
    'City': ['Paris', 'London', 'Berlin', 'London'],
    'Population': [2148271, 8982000, 3645000, 1234567]
})
# loc is label-based
pop_london = df.loc[df['City'] == 'London', 'Population']
print(pop_london)

# or you can use a mask with .loc
mask = df['City'].eq('London')
pop_london_mask = df.loc[mask, 'Population']
print(pop_london_mask)

----

Output:
[source,python]
----
1    8982000
3    1234567
Name: Population, dtype: int64
----

.How it works:
Loc parses its two arguments as follows:
* .loc sees a boolean array on the first axis, keeps all rows whose mask element is True, and then returns the Population column of those rows.
Example:
* 0 False
* 1 True
* 2 False


*When to Use:*  
- Selecting rows and columns by labels or boolean conditions.

*When Not to Use:*  
- Pure index-based selection; use .iloc instead.

==== .iloc[row, col]
.Index-based (positional) data selection.
[source,python]
----
import pandas as pd

df = pd.DataFrame({
    'City': ['Paris', 'London', 'Berlin', 'London'],
    'Population': [2148271, 8982000, 3645000, 1234567]
})

#iloc is index-based
pop_london_iloc = df.iloc[2, :]  # 0 is index of city, 1 is index of population, use : to select all columns
print(pop_london_iloc)
----
.Output:
[source,python]
----
City           Berlin
Population    3645000
Name: 2, dtype: object
----
.Or if you want to make it the same as .loc where it returns all the rows that passed the condition:
[source,python]
----
# convert the column label to its positional index
pop_idx = df.columns.get_loc('Population')
# Alternatively, to use .iloc, convert the mask to integer positions:
row_indices = mask[mask].index
# same rows/column as your .loc version
pop_london = df.iloc[row_indices, pop_idx]
print(pop_london)
----
.Output:
[source,python]
----
1    8982000
3    1234567
Name: Population, dtype: int64
----



*When to Use:*  
- Access by integer positions (like array indexing).

*When Not to Use:*  
- Selecting by label or condition; use .loc instead.

==== .at[row, col]
.Fast label-based single value access.
[source,python]
----
selected_idx = 1
val = df.at[selected_idx, 'City']  # Accessing the Population of London using label
val2 = df.at[selected_idx, 'Population']  # Accessing the Population of London using label
print(val, val2)
----
.Output:
[source,python]
----
London 8982000
----
*When to Use:*  
- Optimized for retrieving a single value at known row and column labels.

*When Not to Use:*  
- Selecting multiple rows or columns at once.


==== .iat[row, col]

.Fast index-based single value access.
[source,python]
----
london_pop = df.iat[1, 1]  # Accessing the Population of London using index
print(london_pop)  
----

.Output:
[source,python]
----
8982000
----
*When to Use:*  
- Optimized for retrieving a single value at known row and column positions.

*When Not to Use:*  
- Selecting by label or for retrieving multiple values.




==== Boolean Masks
.Boolean masks are a powerful feature in pandas that allow you to filter DataFrames based on specific conditions.
[source,python]
----
mask = df['Population'] >= 3000000
filtered_df = df[mask]
print(filtered_df.iloc[::, ::]) # Display all columns, or just use head() to show the first few rows
----
.Output:
[source,python]
----
       City  Population
1   London      8982000
2   Berlin      3645000
----
*When to Use:*  
- When you need to filter data based on specific conditions.

*When Not to Use:*  
- For simple row/column selection; use .loc or .iloc instead.

.One-liner boolean mask:
[source,python]
----
filtered_df = df[df['Population'].ge(8_982_000)]   # .ge == “>=”
----


=== Missing Values
==== df.dropna()
.Removes rows (or columns) that contain missing values.
[source,python]
----
import pandas as pd
import numpy as np

df = pd.DataFrame({
    'Name' : ['Alice', 'Bob',   np.nan, 'Diana', np.nan],
    'Score': [  88 ,   np.nan,   79  ,   90  , np.nan ], 
    'City' : [np.nan, np.nan, np.nan, np.nan, np.nan],
})

print("Original DataFrame:", df.iloc[::,::], sep='\n')

# 1️⃣  Drop any row that has at least one NaN
clean_rows_any = df.dropna()    #default is axis=rows, how ='any'
print('clean rows: ',clean_rows_any, sep='\n')  #this will return empty dataframe because all rows have at least one NaN

clean_rows_all = df.dropna(how='all')   # this will drop rows only if all values are NaN
print('clean rows all: ',clean_rows_all, sep='\n')


# 2️⃣  Drop columns that are all NaN
clean_cols = df.dropna(axis='columns', how='all')
print('clean_col', clean_cols, sep='\n')
----
.Output:
[source,python]
----
Original DataFrame:
    Name  Score  City
0  Alice   88.0   NaN
1    Bob    NaN   NaN
2    NaN   79.0   NaN
3  Diana   90.0   NaN
4    NaN    NaN   NaN
clean rows: 
Empty DataFrame
Columns: [Name, Score, City]
Index: []
clean rows all: 
    Name  Score  City
0  Alice   88.0   NaN
1    Bob    NaN   NaN
2    NaN   79.0   NaN
3  Diana   90.0   NaN
clean_col
    Name  Score
0  Alice   88.0
1    Bob    NaN
2    NaN   79.0
3  Diana   90.0
4    NaN    NaN
----
*When to Use:*  
- You truly want to discard incomplete records (e.g., training a model that cannot handle NaNs).  
- Columns are completely empty and add no information.

*When Not to Use:*  
- The loss of data would harm analysis or create bias.  
- You only need to ignore NaNs temporarily—consider `.fillna()` or model-side handling instead.



==== df.fillna()
.Replaces missing values with a specified constant or computed statistic.
[source,python]
----
import pandas as pd
import numpy as np

df = pd.DataFrame({
    'Product': ['A', 'B', 'C', 'D'],
    'Price'  : [10.5, np.nan, 12.0, np.nan]
})

# 1️⃣  Fill with a scalar
df_fixed = df.fillna(0)
print(df_fixed)

# 2️⃣  Fill with a column mean (common in feature engineering)
mean_price = df['Price'].mean()
df_mean = df.assign(Price=df['Price'].fillna(mean_price))
print(df_mean)
----
.Output:
[source,python]
----
  Product  Price
0       A   10.5
1       B    0.0
2       C   12.0
3       D    0.0

  Product  Price
0       A  10.50
1       B  11.25
2       C  12.00
3       D  11.25
----
*When to Use:*  
- Keeping the row is more valuable than the exact value (e.g., imputing with mean/median).  
- Preparing data for ML algorithms that require complete numeric input.

*When Not to Use:*  
- The placeholder would distort downstream statistics (e.g., filling with 0 when 0 is a valid, meaningful value).  
- Missingness itself carries information—you might add a “_missing” indicator instead.



==== df.isna()
.Returns a Boolean mask indicating missing values (NaN or None).
[source,python]
----
import pandas as pd
import numpy as np

df = pd.DataFrame({
    'City'      : ['Paris', 'London', None,   'Berlin'],
    'Population': [2_148_000, np.nan, 3_645_000, 3_748_000]
})

mask = df.isna()
print(mask)

# Example: count missing cells per column
missing_per_col = mask.sum()
print(missing_per_col)
----
.Output:
[source,python]
----
    City  Population
0  False       False
1  False        True
2   True       False
3  False       False

City          1
Population    1
dtype: int64
----
*When to Use:*  
- Building custom boolean masks for advanced filtering (e.g., `df[df['Population'].isna()]`).  
- Quick diagnostics or QA checks (`df.isna().sum()` for a nulls overview).

*When Not to Use:*  
- Situations requiring the *inverse*—in that case use `.notna()` for readability.  

