{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e178906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe : /home/edward99/github/datenvorbearbeitung/.venv/bin/python\n",
      "pandas     : 2.3.1\n",
      "has pyarrow: True\n",
      "has fparq  : True\n"
     ]
    }
   ],
   "source": [
    "import sys, pandas as pd, importlib.util\n",
    "print(\"Python exe :\", sys.executable)\n",
    "print(\"pandas     :\", pd.__version__)\n",
    "print(\"has pyarrow:\", importlib.util.find_spec(\"pyarrow\") is not None)\n",
    "print(\"has fparq  :\", importlib.util.find_spec(\"fastparquet\") is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "920b6cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     status sex orientation       body_type               diet  \\\n",
      "0   22     single   m    straight  a little extra  strictly anything   \n",
      "1   35     single   m    straight         average       mostly other   \n",
      "2   38  available   m    straight            thin           anything   \n",
      "3   23     single   m    straight            thin         vegetarian   \n",
      "4   29     single   m    straight        athletic               None   \n",
      "\n",
      "     drinks      drugs                          education  \\\n",
      "0  socially      never      working on college/university   \n",
      "1     often  sometimes              working on space camp   \n",
      "2  socially       None     graduated from masters program   \n",
      "3  socially       None      working on college/university   \n",
      "4  socially      never  graduated from college/university   \n",
      "\n",
      "             ethnicity  ...  income                          job  \\\n",
      "0         asian, white  ...      -1               transportation   \n",
      "1                white  ...   80000         hospitality / travel   \n",
      "2                 None  ...      -1                         None   \n",
      "3                white  ...   20000                      student   \n",
      "4  asian, black, other  ...      -1  artistic / musical / writer   \n",
      "\n",
      "        last_online                         location  \\\n",
      "0  2012-06-28-20-30  south san francisco, california   \n",
      "1  2012-06-29-21-41              oakland, california   \n",
      "2  2012-06-27-09-10        san francisco, california   \n",
      "3  2012-06-28-14-22             berkeley, california   \n",
      "4  2012-06-27-21-26        san francisco, california   \n",
      "\n",
      "                                offspring                       pets  \\\n",
      "0  doesn't have kids, but might want them  likes dogs and likes cats   \n",
      "1  doesn't have kids, but might want them  likes dogs and likes cats   \n",
      "2                                    None                   has cats   \n",
      "3                       doesn't want kids                 likes cats   \n",
      "4                                    None  likes dogs and likes cats   \n",
      "\n",
      "                                   religion  \\\n",
      "0     agnosticism and very serious about it   \n",
      "1  agnosticism but not too serious about it   \n",
      "2                                      None   \n",
      "3                                      None   \n",
      "4                                      None   \n",
      "\n",
      "                                 sign     smokes  \\\n",
      "0                              gemini  sometimes   \n",
      "1                              cancer         no   \n",
      "2  pisces but it doesn&rsquo;t matter         no   \n",
      "3                              pisces         no   \n",
      "4                            aquarius         no   \n",
      "\n",
      "                                              speaks  \n",
      "0                                            english  \n",
      "1  english (fluently), spanish (poorly), french (...  \n",
      "2                               english, french, c++  \n",
      "3                           english, german (poorly)  \n",
      "4                                            english  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(59946, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('okcupid_profiles.parquet', engine='fastparquet')\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66faf0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['body_type_a little extra' 'body_type_athletic' 'body_type_average'\n",
      " 'body_type_curvy' 'body_type_fit' 'body_type_full figured'\n",
      " 'body_type_jacked' 'body_type_overweight' 'body_type_rather not say'\n",
      " 'body_type_skinny' 'body_type_thin' 'body_type_used up' 'body_type_None']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Create OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Fit and transform body_type column\n",
    "encoded_data = encoder.fit_transform(df[['body_type']])\n",
    "# Bonus 1: Get feature names\n",
    "feature_names = encoder.get_feature_names_out(['body_type'])\n",
    "print(f\"Feature names: {feature_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d03bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   body_type_a little extra  body_type_athletic  body_type_average  \\\n",
      "0                       1.0                 0.0                0.0   \n",
      "1                       0.0                 0.0                1.0   \n",
      "2                       0.0                 0.0                0.0   \n",
      "3                       0.0                 0.0                0.0   \n",
      "4                       0.0                 1.0                0.0   \n",
      "\n",
      "   body_type_curvy  body_type_fit  body_type_full figured  body_type_jacked  \\\n",
      "0              0.0            0.0                     0.0               0.0   \n",
      "1              0.0            0.0                     0.0               0.0   \n",
      "2              0.0            0.0                     0.0               0.0   \n",
      "3              0.0            0.0                     0.0               0.0   \n",
      "4              0.0            0.0                     0.0               0.0   \n",
      "\n",
      "   body_type_overweight  body_type_rather not say  body_type_skinny  \\\n",
      "0                   0.0                       0.0               0.0   \n",
      "1                   0.0                       0.0               0.0   \n",
      "2                   0.0                       0.0               0.0   \n",
      "3                   0.0                       0.0               0.0   \n",
      "4                   0.0                       0.0               0.0   \n",
      "\n",
      "   body_type_thin  body_type_used up  body_type_None  \n",
      "0             0.0                0.0             0.0  \n",
      "1             0.0                0.0             0.0  \n",
      "2             1.0                0.0             0.0  \n",
      "3             1.0                0.0             0.0  \n",
      "4             0.0                0.0             0.0  \n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with encoded columns\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=feature_names)\n",
    "print(encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01b00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy coded DataFrame: \n",
      "   body_athletic  body_average  body_curvy  body_fit  body_full figured  \\\n",
      "0          False         False       False     False              False   \n",
      "1          False          True       False     False              False   \n",
      "2          False         False       False     False              False   \n",
      "3          False         False       False     False              False   \n",
      "4           True         False       False     False              False   \n",
      "\n",
      "   body_jacked  body_overweight  body_rather not say  body_skinny  body_thin  \\\n",
      "0        False            False                False        False      False   \n",
      "1        False            False                False        False      False   \n",
      "2        False            False                False        False       True   \n",
      "3        False            False                False        False       True   \n",
      "4        False            False                False        False      False   \n",
      "\n",
      "   body_used up  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n"
     ]
    }
   ],
   "source": [
    "#Dummy Coding\n",
    "dummies = pd.get_dummies(df[\"body_type\"], prefix=\"body\", drop_first=True)\n",
    "df_dummy = pd.concat([df.drop(columns=[\"body_type\"]), dummies], axis=1)\n",
    "\n",
    "print(\"Dummy coded DataFrame: \", dummies.head(), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccedf777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect coded DataFrame: \n",
      "  body_athletic body_average body_curvy body_fit body_full figured  \\\n",
      "0            -1           -1         -1       -1                -1   \n",
      "1         False         True      False    False             False   \n",
      "2         False        False      False    False             False   \n",
      "3         False        False      False    False             False   \n",
      "4          True        False      False    False             False   \n",
      "\n",
      "  body_jacked body_overweight body_rather not say body_skinny body_thin  \\\n",
      "0          -1              -1                  -1          -1        -1   \n",
      "1       False           False               False       False     False   \n",
      "2       False           False               False       False      True   \n",
      "3       False           False               False       False      True   \n",
      "4       False           False               False       False     False   \n",
      "\n",
      "  body_used up  \n",
      "0           -1  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n",
      "/tmp/ipykernel_96996/1784277241.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dummies.loc[ref_mask, :] = -1\n"
     ]
    }
   ],
   "source": [
    "#Effect Coding\n",
    "import pandas as pd\n",
    "\n",
    "def effect_code(series: pd.Series, prefix=\"x\"):\n",
    "    \"\"\"Return an effect–coded DataFrame (K-1 columns, 1/0/-1).\"\"\"\n",
    "    dummies = pd.get_dummies(series, prefix=prefix, drop_first=True)\n",
    "    # rows that were dropped_first() become the reference --> turn the 0s into -1\n",
    "    ref_mask = (~series.isna()) & (dummies.sum(axis=1) == 0)\n",
    "    dummies.loc[ref_mask, :] = -1\n",
    "    return dummies\n",
    "\n",
    "ec = effect_code(df[\"body_type\"], prefix=\"body\")\n",
    "df_ec = pd.concat([df.drop(columns=\"body_type\"), ec], axis=1)\n",
    "print(\"Effect coded DataFrame: \", ec.head(), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22465d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   body_a little extra  body_athletic  body_average  body_curvy  body_fit  \\\n",
      "0                 True          False         False       False     False   \n",
      "1                False          False          True       False     False   \n",
      "\n",
      "   body_full figured  body_jacked  body_other  body_overweight  body_skinny  \\\n",
      "0              False        False       False            False        False   \n",
      "1              False        False       False            False        False   \n",
      "\n",
      "   body_thin  body_used up  \n",
      "0      False         False  \n",
      "1      False         False  \n"
     ]
    }
   ],
   "source": [
    "# Effect Coding\n",
    "def frequency_cutoff(series: pd.Series, min_count: int = 100) -> pd.Series:\n",
    "    \"\"\"Replace infrequent levels by 'other'.\"\"\"\n",
    "    vc = series.value_counts()\n",
    "    return series.where(series.map(vc) >= min_count, other=\"other\")\n",
    "\n",
    "df[\"body_type_cut\"] = frequency_cutoff(df[\"body_type\"], min_count=200)\n",
    "dummies = pd.get_dummies(df[\"body_type_cut\"], prefix=\"body\")\n",
    "\n",
    "print(dummies.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99ecc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded DataFrame with OHE: \n",
      "   body_type_athletic  body_type_average  body_type_curvy  body_type_fit  \\\n",
      "0                 0.0                0.0              0.0            0.0   \n",
      "1                 0.0                1.0              0.0            0.0   \n",
      "\n",
      "   body_type_full figured  body_type_jacked  body_type_overweight  \\\n",
      "0                     0.0               0.0                   0.0   \n",
      "1                     0.0               0.0                   0.0   \n",
      "\n",
      "   body_type_skinny  body_type_thin  body_type_used up  body_type_None  \\\n",
      "0               0.0             0.0                0.0             0.0   \n",
      "1               0.0             0.0                0.0             0.0   \n",
      "\n",
      "   body_type_infrequent_sklearn  \n",
      "0                           0.0  \n",
      "1                           0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "        handle_unknown=\"infrequent_if_exist\",\n",
    "        min_frequency=200,   # absolute cut-off\n",
    "        drop=\"first\"         # optional: keeps dummy coding\n",
    ")\n",
    "X_encoded = ohe.fit_transform(df[[\"body_type\"]])\n",
    "print(\"Encoded DataFrame with OHE: \", pd.DataFrame(X_encoded.toarray(), columns=ohe.get_feature_names_out()).head(2), sep=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffde8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame:\n",
      "\n",
      "  body_type  liked\n",
      "0   average      1\n",
      "1  athletic      0\n",
      "2   average      1\n",
      "3     curvy      0\n",
      "4  athletic      1\n",
      "5      thin      1\n",
      "6     curvy      0\n",
      "7   average      1\n",
      "liked      non_like  like  total      odds_num\n",
      "body_type                                     \n",
      "athletic          1     1      2  9.999990e-01\n",
      "average           0     3      3  3.000000e+06\n",
      "curvy             2     0      2  0.000000e+00\n",
      "thin              0     1      1  1.000000e+06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# toy sample ─────────────────────────────────────────────\n",
    "df = pd.DataFrame({\n",
    "    \"body_type\": [\"average\", \"athletic\", \"average\", \"curvy\",\n",
    "                  \"athletic\", \"thin\", \"curvy\", \"average\"],\n",
    "    \"liked\":     [1,          0,          1,        0,\n",
    "                  1,          1,       0,        1]       # 1 = liked, 0 = skipped\n",
    "})\n",
    "print(\"Sample DataFrame:\\n\", df, sep=\"\\n\")\n",
    "\n",
    "# 1) build the 2-way contingency table\n",
    "ct = (\n",
    "    pd.crosstab(df.body_type, df.liked)\n",
    "      .rename(columns={0: \"non_like\", 1: \"like\"})\n",
    "      .assign(                                  # extra stats we care about\n",
    "          total     = lambda x: x.like + x.non_like,\n",
    "          # numerator of odds ratio  = like / (non_like + ε)\n",
    "          odds_num  = lambda x: x.like / (x.non_like + 1e-6)\n",
    "      )\n",
    ")\n",
    "\n",
    "print(ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a675c424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-fold CV accuracy: 0.75\n",
      "\n",
      "encoded test rows:\n",
      "[[0.e+00 0.e+00]\n",
      " [2.e+00 2.e+06]]\n",
      "\n",
      "predicted probabilities (like=1):\n",
      "[0.25932963 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward99/github/datenvorbearbeitung/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bin-count (target) encoding demo\n",
    "✓ high-cardinality categorical → dense numeric columns\n",
    "✓ no target leakage inside CV\n",
    "✓ works end-to-end in an sklearn Pipeline\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. toy data ─ exactly the little body_type / liked table you typed\n",
    "# ---------------------------------------------------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"body_type\": [\"average\", \"athletic\", \"average\", \"curvy\",\n",
    "                  \"athletic\", \"thin\", \"curvy\", \"average\"],\n",
    "    \"liked\":     [1, 0, 1, 0, 1, 1, 0, 1]\n",
    "})\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. helpers to create look-up tables   (fit on *training* data only!)\n",
    "# ---------------------------------------------------------------------\n",
    "def _build_lookups(series: pd.Series, y: pd.Series,\n",
    "                   min_count: int = 1, eps: float = 1e-6):\n",
    "    \"\"\"return two dicts: positive counts, odds numerator\"\"\"\n",
    "    vc = series.value_counts()\n",
    "    safe = series.where(series.map(vc) >= min_count, other=\"other\")\n",
    "\n",
    "    ct = pd.crosstab(safe, y)              # rows = category, cols = {0,1}\n",
    "    ct = ct.rename(columns={0: \"neg\", 1: \"pos\"})\n",
    "\n",
    "    pos_cnt  = ct[\"pos\"].to_dict()\n",
    "    neg_cnt  = ct[\"neg\"].to_dict()\n",
    "    odds_num = {k: pos_cnt[k] / (neg_cnt.get(k, 0) + eps) for k in ct.index}\n",
    "    return pos_cnt, odds_num\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3. proper sklearn transformer   (stateless once look-ups are given)\n",
    "# ---------------------------------------------------------------------\n",
    "class BinCountEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Replace a single categorical column by\n",
    "    – positive count\n",
    "    – odds-numerator  (= pos / neg)\n",
    "    \"\"\"\n",
    "    def __init__(self, min_count: int = 30):\n",
    "        self.min_count = min_count\n",
    "        # placeholders – filled in fit()\n",
    "        self._pos_lookup = None\n",
    "        self._odds_lookup = None\n",
    "        self._feat_names = np.array([\"bin_pos_cnt\", \"bin_odds_num\"])\n",
    "\n",
    "    # sklearn API ------------------------------------------------------\n",
    "    def fit(self, X, y):\n",
    "        # X arrives as DataFrame with ONE column\n",
    "        cat = X.iloc[:, 0]\n",
    "        self._pos_lookup, self._odds_lookup = _build_lookups(\n",
    "            cat, y, min_count=self.min_count\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        cat = X.iloc[:, 0]\n",
    "        pos  = cat.map(self._pos_lookup).fillna(self._pos_lookup.get(\"other\", 0))\n",
    "        odds = cat.map(self._odds_lookup).fillna(self._odds_lookup.get(\"other\", 0.0))\n",
    "        return np.vstack([pos, odds]).T             # shape (n_samples, 2)\n",
    "\n",
    "    def get_feature_names_out(self, in_names=None):\n",
    "        return self._feat_names\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4. pipeline  → safe CV without leakage\n",
    "# ---------------------------------------------------------------------\n",
    "pipe = Pipeline([\n",
    "    (\"bin\",  BinCountEncoder(min_count=1)),   # 1 for this tiny example\n",
    "    (\"clf\",  LogisticRegression(solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "print(\"4-fold CV accuracy:\",\n",
    "      cross_val_score(pipe, df[[\"body_type\"]], df[\"liked\"],\n",
    "                      cv=4, scoring=\"accuracy\").mean())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5. train / inference example\n",
    "# ---------------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[\"body_type\"]], df[\"liked\"], test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"\\nencoded test rows:\")\n",
    "print(pipe.named_steps[\"bin\"].transform(X_test))\n",
    "\n",
    "print(\"\\npredicted probabilities (like=1):\")\n",
    "print(pipe.predict_proba(X_test)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd0e3f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique body types (using .unique()):\n",
      "['a little extra' 'average' 'thin' 'athletic' 'fit' None 'skinny' 'curvy'\n",
      " 'full figured' 'jacked' 'rather not say' 'used up' 'overweight']\n",
      "\n",
      "Body type counts (using .value_counts()):\n",
      "body_type\n",
      "average           14652\n",
      "fit               12711\n",
      "athletic          11819\n",
      "thin               4711\n",
      "curvy              3924\n",
      "a little extra     2629\n",
      "skinny             1777\n",
      "full figured       1009\n",
      "overweight          444\n",
      "jacked              421\n",
      "used up             355\n",
      "rather not say      198\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total number of unique body types: 12\n",
      "\n",
      "Unique body types (using set()):\n",
      "{'average', 'a little extra', 'jacked', 'full figured', 'athletic', 'skinny', 'curvy', 'overweight', 'rather not say', 'thin', 'fit', 'used up'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique body types (using .unique()):\")\n",
    "print(df['body_type'].unique())\n",
    "\n",
    "print(\"\\nBody type counts (using .value_counts()):\")\n",
    "print(df['body_type'].value_counts())\n",
    "\n",
    "print(f\"\\nTotal number of unique body types: {df['body_type'].nunique()}\")\n",
    "\n",
    "print(\"\\nUnique body types (using set()):\")\n",
    "print(set(df['body_type'].dropna()))  # dropna() removes NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f84d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>None</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>None</td>\n",
       "      <td>has cats</td>\n",
       "      <td>None</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>None</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>None</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>None</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>None</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>None</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sales / marketing / biz dev</td>\n",
       "      <td>2012-06-12-21-47</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>has kids</td>\n",
       "      <td>has dogs</td>\n",
       "      <td>catholicism but not too serious about it</td>\n",
       "      <td>cancer and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>entertainment / media</td>\n",
       "      <td>2012-06-29-11-01</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn't have kids</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>leo but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>asian</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>construction / craftsmanship</td>\n",
       "      <td>2012-06-27-23-37</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids</td>\n",
       "      <td>None</td>\n",
       "      <td>christianity but not too serious about it</td>\n",
       "      <td>sagittarius but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, black</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>2012-06-23-13-01</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn't have kids, but wants them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>leo and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>trying to quit</td>\n",
       "      <td>english (fluently), spanish (poorly), chinese ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>None</td>\n",
       "      <td>socially</td>\n",
       "      <td>None</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>2012-06-29-00-42</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>None</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>catholicism and laughing about it</td>\n",
       "      <td>gemini and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     status sex orientation       body_type               diet  \\\n",
       "0       22     single   m    straight  a little extra  strictly anything   \n",
       "1       35     single   m    straight         average       mostly other   \n",
       "2       38  available   m    straight            thin           anything   \n",
       "3       23     single   m    straight            thin         vegetarian   \n",
       "4       29     single   m    straight        athletic               None   \n",
       "...    ...        ...  ..         ...             ...                ...   \n",
       "59941   59     single   f    straight            None               None   \n",
       "59942   24     single   m    straight             fit    mostly anything   \n",
       "59943   42     single   m    straight         average    mostly anything   \n",
       "59944   27     single   m    straight        athletic    mostly anything   \n",
       "59945   39     single   m         gay         average               None   \n",
       "\n",
       "           drinks      drugs                          education  \\\n",
       "0        socially      never      working on college/university   \n",
       "1           often  sometimes              working on space camp   \n",
       "2        socially       None     graduated from masters program   \n",
       "3        socially       None      working on college/university   \n",
       "4        socially      never  graduated from college/university   \n",
       "...           ...        ...                                ...   \n",
       "59941    socially      never  graduated from college/university   \n",
       "59942       often  sometimes      working on college/university   \n",
       "59943  not at all      never     graduated from masters program   \n",
       "59944    socially      often      working on college/university   \n",
       "59945    socially       None     graduated from masters program   \n",
       "\n",
       "                 ethnicity  ...  income                           job  \\\n",
       "0             asian, white  ...      -1                transportation   \n",
       "1                    white  ...   80000          hospitality / travel   \n",
       "2                     None  ...      -1                          None   \n",
       "3                    white  ...   20000                       student   \n",
       "4      asian, black, other  ...      -1   artistic / musical / writer   \n",
       "...                    ...  ...     ...                           ...   \n",
       "59941                 None  ...      -1   sales / marketing / biz dev   \n",
       "59942         white, other  ...      -1         entertainment / media   \n",
       "59943                asian  ...  100000  construction / craftsmanship   \n",
       "59944         asian, black  ...      -1             medicine / health   \n",
       "59945                white  ...      -1             medicine / health   \n",
       "\n",
       "            last_online                         location  \\\n",
       "0      2012-06-28-20-30  south san francisco, california   \n",
       "1      2012-06-29-21-41              oakland, california   \n",
       "2      2012-06-27-09-10        san francisco, california   \n",
       "3      2012-06-28-14-22             berkeley, california   \n",
       "4      2012-06-27-21-26        san francisco, california   \n",
       "...                 ...                              ...   \n",
       "59941  2012-06-12-21-47              oakland, california   \n",
       "59942  2012-06-29-11-01        san francisco, california   \n",
       "59943  2012-06-27-23-37  south san francisco, california   \n",
       "59944  2012-06-23-13-01        san francisco, california   \n",
       "59945  2012-06-29-00-42        san francisco, california   \n",
       "\n",
       "                                    offspring                       pets  \\\n",
       "0      doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1      doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2                                        None                   has cats   \n",
       "3                           doesn't want kids                 likes cats   \n",
       "4                                        None  likes dogs and likes cats   \n",
       "...                                       ...                        ...   \n",
       "59941                                has kids                   has dogs   \n",
       "59942                       doesn't have kids  likes dogs and likes cats   \n",
       "59943                       doesn't have kids                       None   \n",
       "59944       doesn't have kids, but wants them  likes dogs and likes cats   \n",
       "59945                                    None  likes dogs and likes cats   \n",
       "\n",
       "                                        religion  \\\n",
       "0          agnosticism and very serious about it   \n",
       "1       agnosticism but not too serious about it   \n",
       "2                                           None   \n",
       "3                                           None   \n",
       "4                                           None   \n",
       "...                                          ...   \n",
       "59941   catholicism but not too serious about it   \n",
       "59942                                agnosticism   \n",
       "59943  christianity but not too serious about it   \n",
       "59944   agnosticism but not too serious about it   \n",
       "59945          catholicism and laughing about it   \n",
       "\n",
       "                                           sign          smokes  \\\n",
       "0                                        gemini       sometimes   \n",
       "1                                        cancer              no   \n",
       "2            pisces but it doesn&rsquo;t matter              no   \n",
       "3                                        pisces              no   \n",
       "4                                      aquarius              no   \n",
       "...                                         ...             ...   \n",
       "59941  cancer and it&rsquo;s fun to think about              no   \n",
       "59942           leo but it doesn&rsquo;t matter              no   \n",
       "59943   sagittarius but it doesn&rsquo;t matter              no   \n",
       "59944     leo and it&rsquo;s fun to think about  trying to quit   \n",
       "59945  gemini and it&rsquo;s fun to think about       sometimes   \n",
       "\n",
       "                                                  speaks  \n",
       "0                                                english  \n",
       "1      english (fluently), spanish (poorly), french (...  \n",
       "2                                   english, french, c++  \n",
       "3                               english, german (poorly)  \n",
       "4                                                english  \n",
       "...                                                  ...  \n",
       "59941                                            english  \n",
       "59942                                 english (fluently)  \n",
       "59943                                 english (fluently)  \n",
       "59944  english (fluently), spanish (poorly), chinese ...  \n",
       "59945                                            english  \n",
       "\n",
       "[59946 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "# ── 1. create a new column with the hashed values\n",
    "df_copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab143f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashed representation:\n",
      "    h0  h1  h2  h3  h4  h5  h6  h7\n",
      "0   0   0   0   0   0  -1   0   0\n",
      "1   0   0   0   0   0   1   0   0\n",
      "2   0   0   0   0  -1   0   0   0\n",
      "3   0   0   0   0  -1   0   0   0\n",
      "4   0   0   0   1   0   0   0   0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "# ── 2. FeatureHasher expects a list / iterable of {feature_name: value} dicts\n",
    "to_hash = (\n",
    "    df['body_type']\n",
    "      .fillna('missing')          # make sure every key is a str\n",
    "      .astype(str)                # in case something weird slipped through\n",
    "      .apply(lambda s: {s: 1})\n",
    ")\n",
    "hasher  = FeatureHasher(n_features=8, input_type='dict', alternate_sign=True)\n",
    "hashed  = hasher.transform(to_hash)\n",
    "\n",
    "\n",
    "# choose the vector width (power of two is common). 8 buckets   for the demo\n",
    "hasher = FeatureHasher(n_features=8, input_type=\"dict\", alternate_sign=True)\n",
    "hashed = hasher.transform(to_hash)        # sparse CSR matrix\n",
    "\n",
    "# ── 3. wrap for readability  ──────────────────────────────────────────\n",
    "hashed_df = pd.DataFrame(\n",
    "    hashed.toarray().astype(int),          # dense for the print-out\n",
    "    columns=[f\"h{i}\" for i in range(hashed.shape[1])]\n",
    ")\n",
    "print(\"hashed representation:\\n\", hashed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e9c2557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     status sex orientation       body_type               diet  \\\n",
      "0   22     single   m    straight  a little extra  strictly anything   \n",
      "1   35     single   m    straight         average       mostly other   \n",
      "2   38  available   m    straight            thin           anything   \n",
      "3   23     single   m    straight            thin         vegetarian   \n",
      "4   29     single   m    straight        athletic               None   \n",
      "\n",
      "     drinks      drugs                          education  \\\n",
      "0  socially      never      working on college/university   \n",
      "1     often  sometimes              working on space camp   \n",
      "2  socially       None     graduated from masters program   \n",
      "3  socially       None      working on college/university   \n",
      "4  socially      never  graduated from college/university   \n",
      "\n",
      "             ethnicity  ...     smokes  \\\n",
      "0         asian, white  ...  sometimes   \n",
      "1                white  ...         no   \n",
      "2                 None  ...         no   \n",
      "3                white  ...         no   \n",
      "4  asian, black, other  ...         no   \n",
      "\n",
      "                                              speaks h0 h1 h2 h3 h4 h5 h6 h7  \n",
      "0                                            english  0  0  0  0  0 -1  0  0  \n",
      "1  english (fluently), spanish (poorly), french (...  0  0  0  0  0  1  0  0  \n",
      "2                               english, french, c++  0  0  0  0 -1  0  0  0  \n",
      "3                           english, german (poorly)  0  0  0  0 -1  0  0  0  \n",
      "4                                            english  0  0  0  1  0  0  0  0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace df_copy.concat with:\n",
    "df_combined = pd.concat([df_copy, hashed_df], axis=1)\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fa4ac19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>None</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>None</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>None</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white, other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>asian</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, black</td>\n",
       "      <td>...</td>\n",
       "      <td>trying to quit</td>\n",
       "      <td>english (fluently), spanish (poorly), chinese ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>None</td>\n",
       "      <td>socially</td>\n",
       "      <td>None</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56961 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     status sex orientation       body_type               diet  \\\n",
       "0       22     single   m    straight  a little extra  strictly anything   \n",
       "1       35     single   m    straight         average       mostly other   \n",
       "2       38  available   m    straight            thin           anything   \n",
       "3       23     single   m    straight            thin         vegetarian   \n",
       "4       29     single   m    straight        athletic               None   \n",
       "...    ...        ...  ..         ...             ...                ...   \n",
       "59941   59     single   f    straight            None               None   \n",
       "59942   24     single   m    straight             fit    mostly anything   \n",
       "59943   42     single   m    straight         average    mostly anything   \n",
       "59944   27     single   m    straight        athletic    mostly anything   \n",
       "59945   39     single   m         gay         average               None   \n",
       "\n",
       "           drinks      drugs                          education  \\\n",
       "0        socially      never      working on college/university   \n",
       "1           often  sometimes              working on space camp   \n",
       "2        socially       None     graduated from masters program   \n",
       "3        socially       None      working on college/university   \n",
       "4        socially      never  graduated from college/university   \n",
       "...           ...        ...                                ...   \n",
       "59941    socially      never  graduated from college/university   \n",
       "59942       often  sometimes      working on college/university   \n",
       "59943  not at all      never     graduated from masters program   \n",
       "59944    socially      often      working on college/university   \n",
       "59945    socially       None     graduated from masters program   \n",
       "\n",
       "                 ethnicity  ...          smokes  \\\n",
       "0             asian, white  ...       sometimes   \n",
       "1                    white  ...              no   \n",
       "2                     None  ...              no   \n",
       "3                    white  ...              no   \n",
       "4      asian, black, other  ...              no   \n",
       "...                    ...  ...             ...   \n",
       "59941                 None  ...              no   \n",
       "59942         white, other  ...              no   \n",
       "59943                asian  ...              no   \n",
       "59944         asian, black  ...  trying to quit   \n",
       "59945                white  ...       sometimes   \n",
       "\n",
       "                                                  speaks h0 h1 h2 h3 h4 h5 h6  \\\n",
       "0                                                english  0  0  0  0  0 -1  0   \n",
       "1      english (fluently), spanish (poorly), french (...  0  0  0  0  0  1  0   \n",
       "2                                   english, french, c++  0  0  0  0 -1  0  0   \n",
       "3                               english, german (poorly)  0  0  0  0 -1  0  0   \n",
       "4                                                english  0  0  0  1  0  0  0   \n",
       "...                                                  ... .. .. .. .. .. .. ..   \n",
       "59941                                            english  0  0  0  0  0  0 -1   \n",
       "59942                                 english (fluently)  0  1  0  0  0  0  0   \n",
       "59943                                 english (fluently)  0  0  0  0  0  1  0   \n",
       "59944  english (fluently), spanish (poorly), chinese ...  0  0  0  1  0  0  0   \n",
       "59945                                            english  0  0  0  0  0  1  0   \n",
       "\n",
       "      h7  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "...   ..  \n",
       "59941  0  \n",
       "59942  0  \n",
       "59943  0  \n",
       "59944  0  \n",
       "59945  0  \n",
       "\n",
       "[56961 rows x 29 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask       = df_combined['drinks'].notna()        # keeps only real strings\n",
    "df_clean   = df_combined[mask].copy()\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7df7b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (45568, 28)\n",
      "Test set shape: (11393, 28)\n"
     ]
    }
   ],
   "source": [
    "y = df_clean['drinks']\n",
    "X = df_clean.drop(columns=['drinks'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1bdb1889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7335205828140086\n",
      "f1_macro : 0.1410464135021097\n",
      "\n",
      "full report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " desperately       0.00      0.00      0.00        64\n",
      "  not at all       0.00      0.00      0.00       653\n",
      "       often       0.00      0.00      0.00      1033\n",
      "      rarely       0.00      0.00      0.00      1192\n",
      "    socially       0.73      1.00      0.85      8357\n",
      "  very often       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           0.73     11393\n",
      "   macro avg       0.12      0.17      0.14     11393\n",
      "weighted avg       0.54      0.73      0.62     11393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward99/github/datenvorbearbeitung/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/edward99/github/datenvorbearbeitung/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/edward99/github/datenvorbearbeitung/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "# 1. fit a model ───────────────────────────────────────────────\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")   # always predicts the most common class\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# 2. predict on the held-out test set ──────────────────────────\n",
    "y_pred = dummy.predict(X_test)\n",
    "\n",
    "# 3. evaluate ─────────────────────────────────────────────────\n",
    "print(\"accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_macro :\", f1_score(y_test, y_pred, average=\"macro\"))  # suitable for multi-class\n",
    "print(\"\\nfull report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e64d13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro : 0.1410464135021097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward99/github/datenvorbearbeitung/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# example: one-hot all object-dtype columns, leave numeric columns unchanged\n",
    "cat_cols  = X_train.select_dtypes(include=\"object\").columns\n",
    "num_cols  = X_train.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\",                         num_cols)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "        (\"prep\", pre),\n",
    "        (\"clf\",  LogisticRegression(max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"f1_macro :\", f1_score(y_test, y_pred, average=\"macro\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
