{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    south san francisco, california\n",
      "1                oakland, california\n",
      "2          san francisco, california\n",
      "3               berkeley, california\n",
      "4          san francisco, california\n",
      "Name: location, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "df = pd.read_parquet('okcupid_profiles.parquet', engine='fastparquet')\n",
    "print(df['location'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9442cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: 199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Create OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Fit and transform location column\n",
    "encoded_data = encoder.fit_transform(df[['location']])\n",
    "# Bonus 1: Get feature names\n",
    "feature_names = encoder.get_feature_names_out(['location'])\n",
    "print(f\"Feature names: {len(feature_names)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae938a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 3 hashed rows:\n",
      "   hash_0  hash_1  hash_2  hash_3  hash_4  hash_5  hash_6  hash_7  hash_8  \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   hash_9  ...  hash_246  hash_247  hash_248  hash_249  hash_250  hash_251  \\\n",
      "0     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   hash_252  hash_253  hash_254  hash_255  \n",
      "0       0.0       0.0       0.0       0.0  \n",
      "1       0.0       0.0       0.0       0.0  \n",
      "2       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[3 rows x 256 columns]\n",
      "final shape with hashed columns -> (59946, 276)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Coerce location to str, fill missing with a sentinel\n",
    "location_str = df[\"location\"].fillna(\"missing\").astype(str)\n",
    "\n",
    "# 3. Build list-of-strings format  (simplest)\n",
    "samples = location_str.to_list()          # length = n_rows\n",
    "samples = [[s] for s in samples]      # each sample must be an *iterable* of str\n",
    "\n",
    "# 4. Feature hashing: 2⁸ = 256 buckets with signed hash\n",
    "hasher = FeatureHasher(\n",
    "    n_features=256,          # power of two makes modulo cheap; tune as needed\n",
    "    input_type=\"string\",\n",
    "    alternate_sign=True      # +1 / –1 collisions cancel instead of always adding\n",
    ")\n",
    "\n",
    "hashed = hasher.transform(samples)     # sparse CSR matrix  (n_rows × 256)\n",
    "\n",
    "# 5. Wrap in a DataFrame (dense just for the demo print-out)\n",
    "hashed_df = pd.DataFrame(\n",
    "    hashed.toarray(),                  # keep sparse in real pipelines!\n",
    "    columns=[f\"hash_{i}\" for i in range(hashed.shape[1])],\n",
    "    index=df.index\n",
    ")\n",
    "print(\"first 3 hashed rows:\")\n",
    "print(hashed_df.head(3))\n",
    "\n",
    "# 6. Stick back onto the original frame (drop location if you’re done)\n",
    "df_hashed = pd.concat([df.drop(columns=\"location\"), hashed_df], axis=1)\n",
    "print(\"final shape with hashed columns ->\", df_hashed.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
