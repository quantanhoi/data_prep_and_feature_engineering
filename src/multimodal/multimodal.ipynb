{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33a1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 14:33:11.306279: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-06 14:33:11.324539: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-06 14:33:11.454938: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-06 14:33:11.566081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751805191.661189    8724 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751805191.687270    8724 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751805191.905197    8724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751805191.905216    8724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751805191.905218    8724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751805191.905219    8724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-06 14:33:11.927909: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Input, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e69a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nWhat is a Flatten Layer?\\n========================\\nThe Flatten layer reshapes multi-dimensional data into a single vector for each input sample.\\nThis is often needed before:\\n- Concatenating with other features\\n- Passing data to dense layers\\n\\nHow It Works - Example:\\n----------------------\\nLet's say after an Embedding layer you have:\\n- Output shape: (batch_size, 4, 3)\\n- Meaning: For each sample, you have 4 tokens, each represented by a 3-dimensional embedding\\n\\nBefore Flattening:\\n# One sample looks like this (a 4x3 matrix):\\n# [\\n#   [0.1, 0.2, 0.3],   # Token 1\\n#   [0.4, 0.5, 0.6],   # Token 2\\n#   [0.7, 0.8, 0.9],   # Token 3\\n#   [1.0, 1.1, 1.2]    # Token 4\\n# ]\\n\\nAfter Flattening:\\n# The same sample becomes a single vector:\\n# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\\n# Length: 4 × 3 = 12\\n\\nWhy Use It?\\n-----------\\nThe Flatten layer is crucial because:\\n1. Dense layers expect 1D input - they can't directly process 2D or 3D tensors\\n2. Feature concatenation - when combining different data types (text, numerical, categorical), \\n   you need everything in the same format\\n3. Simplifies architecture - converts complex tensor shapes into simple vectors\\n\\nExample Usage:\\n-------------\\n# For images (28x28 grayscale)\\nlayers.Flatten(input_shape=(28, 28))\\n# This converts a 28x28 matrix into a 784-element vector\\n\\nKey Insight:\\n-----------\\nThe Flatten layer converts each sample from a matrix or tensor into a single vector, \\nmaking it easier to combine with other features.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_data = {\n",
    "    \"review_text\": [\"The food was great, but it took forever to get seated.\", \"The tacos were life changing.\", \"This food made me question the presence of my taste buds.\"],\n",
    "    \"meal_type\": [\"lunch\", \"dinner\", \"dinner\"],\n",
    "    \"meal_total\": [50, 75, 60],\n",
    "    \"rating\": [4, 5, 1]\n",
    "}\n",
    "\"\"\" \n",
    "The multimodal input design pattern addresseses the challenge of representing different types of data or data with complex structures\n",
    "The key idea is to concatenate all available data representations, such as text, images, numerical features or categorical variables into a single combined input for a model.\n",
    "This approach enables machine learning models to make use of diverse information sources, within a unified framework.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "In a restaurant review example, the model can use both numerical and categorical metadata about the meal\n",
    "\n",
    "- Categorical data: meal type (lunch, dinner) => one-hot encoded [0, 0 , 1] for dinner\n",
    "- Numerical data: meal total (price) (30.5 euro)\n",
    "- Combined feature vector => concatenate the one-hot vector and the numerical vector: [0, 0, 1, 30.5]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the input layers\n",
    "\"\"\" \n",
    "What is a Flatten Layer?\n",
    "========================\n",
    "The Flatten layer reshapes multi-dimensional data into a single vector for each input sample.\n",
    "This is often needed before:\n",
    "- Concatenating with other features\n",
    "- Passing data to dense layers\n",
    "\n",
    "How It Works - Example:\n",
    "----------------------\n",
    "Let's say after an Embedding layer you have:\n",
    "- Output shape: (batch_size, 4, 3)\n",
    "- Meaning: For each sample, you have 4 tokens, each represented by a 3-dimensional embedding\n",
    "\n",
    "Before Flattening:\n",
    "# One sample looks like this (a 4x3 matrix):\n",
    "# [\n",
    "#   [0.1, 0.2, 0.3],   # Token 1\n",
    "#   [0.4, 0.5, 0.6],   # Token 2\n",
    "#   [0.7, 0.8, 0.9],   # Token 3\n",
    "#   [1.0, 1.1, 1.2]    # Token 4\n",
    "# ]\n",
    "\n",
    "After Flattening:\n",
    "# The same sample becomes a single vector:\n",
    "# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "# Length: 4 × 3 = 12\n",
    "\n",
    "Why Use It?\n",
    "-----------\n",
    "The Flatten layer is crucial because:\n",
    "1. Dense layers expect 1D input - they can't directly process 2D or 3D tensors\n",
    "2. Feature concatenation - when combining different data types (text, numerical, categorical), \n",
    "   you need everything in the same format\n",
    "3. Simplifies architecture - converts complex tensor shapes into simple vectors\n",
    "\n",
    "Example Usage:\n",
    "-------------\n",
    "# For images (28x28 grayscale)\n",
    "layers.Flatten(input_shape=(28, 28))\n",
    "# This converts a 28x28 matrix into a 784-element vector\n",
    "\n",
    "Key Insight:\n",
    "-----------\n",
    "The Flatten layer converts each sample from a matrix or tensor into a single vector, \n",
    "making it easier to combine with other features.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967715bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9 10 11  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 12 13 14 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [16  2 17 18 19  1 20 21 22 23 24  0  0  0  0  0  0  0  0  0]]\n",
      "one hot meal: [[0, 1, 0], [0, 0, 1], [0, 0, 1]]\n",
      "[[ 0  1  0 50]\n",
      " [ 0  0  1 75]\n",
      " [ 0  0  1 60]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Text preprocessing with a fixed vocabulary size\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Limit tokenizer to the top 50 most frequent words\n",
    "vocab_size = 50\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size)\n",
    "# Build the word‐to‐index mapping based on review_text\n",
    "tokenize.fit_on_texts(reviews_data[\"review_text\"])\n",
    "\n",
    "# Convert each review into a sequence of integer token IDs\n",
    "reviews_train = tokenize.texts_to_sequences(reviews_data[\"review_text\"])\n",
    "# Enforce a fixed sequence length of 20 tokens per review\n",
    "max_sequence_len = 20\n",
    "# Pad shorter sequences with 0s at the end (\"post\") to reach length 20\n",
    "reviews_train = keras.preprocessing.sequence.pad_sequences(\n",
    "    reviews_train, maxlen=max_sequence_len, padding=\"post\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# word = tokenize.index_word[reviews_train[0][0]]  # Get the word corresponding to the first token ID\n",
    "# print(word)\n",
    "\n",
    "\n",
    "\n",
    "# Inspect the padded integer sequences\n",
    "print(reviews_train)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# One-hot encoding of categorical “meal_type” feature\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "possible_meal_vocab = ['breakfast', 'lunch', 'dinner']\n",
    "one_hot_meals = []\n",
    "for meal in reviews_data['meal_type']:\n",
    "    # start with all zeros\n",
    "    one_hot_arr = [0] * len(possible_meal_vocab)\n",
    "    # set the index corresponding to this meal to 1\n",
    "    one_hot_arr[possible_meal_vocab.index(meal)] = 1\n",
    "    one_hot_meals.append(one_hot_arr)\n",
    "\n",
    "# Combine one-hot vectors with the numeric “meal_total” feature\n",
    "tabular_features = np.concatenate(\n",
    "    (\n",
    "        np.array(one_hot_meals),                                   # shape: (batch, 3)\n",
    "        np.expand_dims(reviews_data[\"meal_total\"], axis=1),        # shape: (batch, 1)\n",
    "    ),\n",
    "    axis=1,                                                        # final shape: (batch, 4)\n",
    ")\n",
    "print(\"one hot meal:\", one_hot_meals)\n",
    "\n",
    "# View the assembled tabular feature matrix\n",
    "print(tabular_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Define inputs and embedding for the NLP branch\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "batch_size = len(reviews_data['review_text'])  # number of samples\n",
    "\n",
    "# Input layer for text sequences of length 20\n",
    "embedding_input = Input(shape=(max_sequence_len,))\n",
    "# Embedding layer: maps each token ID to a 64-dim dense vector\n",
    "# Note: input_dim=batch_size is just for demo; in practice use vocab_size+1\n",
    "embedding_layer = Embedding(input_dim=batch_size, output_dim=64)(embedding_input)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Define inputs and dense transform for the tabular branch\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "tabular_input = Input(shape=(tabular_features.shape[1],))  # (batch, 4)\n",
    "# Dense layer to process combined one-hot + numeric features\n",
    "tabular_layer = Dense(32, activation='relu')(tabular_input)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Merge the two branches and build the final model\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Concatenate text embeddings (batch, 20, 64) with tabular output (batch, 4)\n",
    "merged_input = keras.layers.concatenate([embedding_layer, tabular_layer])\n",
    "# Add a hidden dense layer\n",
    "merged_dense = Dense(16, activation='relu')(merged_input)\n",
    "# Final output: single continuous prediction (e.g. rating)\n",
    "output = Dense(1)(merged_dense)\n",
    "\n",
    "# Instantiate the Model with two inputs and one output\n",
    "model = Model(inputs=[embedding_input, tabular_input], outputs=output)\n",
    "\n",
    "# Preview architecture: input/output shapes and parameter counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec89ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
