{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Input, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e69a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = {\n",
    "    \"review_text\": [\"The food was great, but it took forever to get seated.\", \"The tacos were life changing.\", \"This food made me question the presence of my taste buds.\"],\n",
    "    \"meal_type\": [\"lunch\", \"dinner\", \"dinner\"],\n",
    "    \"meal_total\": [50, 75, 60],\n",
    "    \"rating\": [4, 5, 1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967715bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Text preprocessing with a fixed vocabulary size\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Limit tokenizer to the top 50 most frequent words\n",
    "vocab_size = 50\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size)\n",
    "# Build the word‐to‐index mapping based on review_text\n",
    "tokenize.fit_on_texts(reviews_data[\"review_text\"])\n",
    "\n",
    "# Convert each review into a sequence of integer token IDs\n",
    "reviews_train = tokenize.texts_to_sequences(reviews_data[\"review_text\"])\n",
    "# Enforce a fixed sequence length of 20 tokens per review\n",
    "max_sequence_len = 20\n",
    "# Pad shorter sequences with 0s at the end (\"post\") to reach length 20\n",
    "reviews_train = keras.preprocessing.sequence.pad_sequences(\n",
    "    reviews_train, maxlen=max_sequence_len, padding=\"post\"\n",
    ")\n",
    "\n",
    "# Inspect the padded integer sequences\n",
    "print(reviews_train)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# One-hot encoding of categorical “meal_type” feature\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "possible_meal_vocab = ['breakfast', 'lunch', 'dinner']\n",
    "one_hot_meals = []\n",
    "for meal in reviews_data['meal_type']:\n",
    "    # start with all zeros\n",
    "    one_hot_arr = [0] * len(possible_meal_vocab)\n",
    "    # set the index corresponding to this meal to 1\n",
    "    one_hot_arr[possible_meal_vocab.index(meal)] = 1\n",
    "    one_hot_meals.append(one_hot_arr)\n",
    "\n",
    "# Combine one-hot vectors with the numeric “meal_total” feature\n",
    "tabular_features = np.concatenate(\n",
    "    (\n",
    "        np.array(one_hot_meals),                                   # shape: (batch, 3)\n",
    "        np.expand_dims(reviews_data[\"meal_total\"], axis=1),        # shape: (batch, 1)\n",
    "    ),\n",
    "    axis=1,                                                        # final shape: (batch, 4)\n",
    ")\n",
    "\n",
    "# View the assembled tabular feature matrix\n",
    "print(tabular_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Define inputs and embedding for the NLP branch\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "batch_size = len(reviews_data['review_text'])  # number of samples\n",
    "\n",
    "# Input layer for text sequences of length 20\n",
    "embedding_input = Input(shape=(max_sequence_len,))\n",
    "# Embedding layer: maps each token ID to a 64-dim dense vector\n",
    "# Note: input_dim=batch_size is just for demo; in practice use vocab_size+1\n",
    "embedding_layer = Embedding(input_dim=batch_size, output_dim=64)(embedding_input)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Define inputs and dense transform for the tabular branch\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "tabular_input = Input(shape=(tabular_features.shape[1],))  # (batch, 4)\n",
    "# Dense layer to process combined one-hot + numeric features\n",
    "tabular_layer = Dense(32, activation='relu')(tabular_input)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Merge the two branches and build the final model\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Concatenate text embeddings (batch, 20, 64) with tabular output (batch, 4)\n",
    "merged_input = keras.layers.concatenate([embedding_layer, tabular_layer])\n",
    "# Add a hidden dense layer\n",
    "merged_dense = Dense(16, activation='relu')(merged_input)\n",
    "# Final output: single continuous prediction (e.g. rating)\n",
    "output = Dense(1)(merged_dense)\n",
    "\n",
    "# Instantiate the Model with two inputs and one output\n",
    "model = Model(inputs=[embedding_input, tabular_input], outputs=output)\n",
    "\n",
    "# Preview architecture: input/output shapes and parameter counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec89ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
